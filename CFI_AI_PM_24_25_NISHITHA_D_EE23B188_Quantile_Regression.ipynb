{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "tbeSMtFzaFbs"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HGFJ1pQsP8VN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "aVmsGWUFd-tP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VMJ4av3_YGjM",
        "outputId": "bf3d593e-2418-4ed1-8cc3-1773e012979b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "!pip3 install pyprind\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "hUT0FSfTbvoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instructions\n",
        "\n",
        "* Clone the notebook to your drive.\n",
        "* The notebook has to be submitted in the form of a link giving us **view access**. Share this link in your application.\n",
        "\n",
        "* If you still have any queries, you can reach out to the [core team](https://www.notion.so/Club-Contacts-70a4823e0ae34f35a0aa5d479e449915)\n",
        "\n"
      ],
      "metadata": {
        "id": "q3APxWObeA_c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Common Technical Questionnaire\n"
      ],
      "metadata": {
        "id": "h0ojuzzfedsb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1\n",
        "\n",
        "Supervised learning is a type of machine learning where the inputs and outputs are mapped through\n",
        "a family of equations, the machine learning model essentially picks the right curve to fit the data.\n",
        "Quantile Regression is a type of supervised learning technique used in statistics and economics. One\n",
        "advantage of quantile regression relative to ordinary least squares regression is that the quantile\n",
        "regression estimates are more robust against outliers in the response measurements.\n",
        "\n",
        "QuantileLossτ (y, ˆy) =\n",
        "{\n",
        "\n",
        "                           τ · (y − ˆy) if y > ˆy\n",
        "\n",
        "                          (1 − τ ) · (ˆy − y) if y ≤ ˆy\n",
        "}\n",
        "\n",
        "where τ is Quantile whose value lies between 0 and 1.\n",
        "Please use this template provided and make changes accordingly for this question alone.\n",
        "Implement a simple Neural Network consisting of 4 nodes, one hidden layer consisting of 5 nodes\n",
        "and output layer consisting of two nodes. Perform quantile regression on the model and observe\n",
        "the loss.\n",
        "**Bonus: Play around with the value of τ to find what value achieves convergence quicker.**\n",
        "\n"
      ],
      "metadata": {
        "id": "IFnXRXAWVSkZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An example implementation of a simple manual neural network is provided. You may use this as inspiration to complete the task at hand."
      ],
      "metadata": {
        "id": "7bKBykeUZtMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "y5YhkW3jE58O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand((2, 4), requires_grad=False)\n",
        "y = torch.rand((2, 2), requires_grad=False)\n",
        "print(x,\"\\n\",y)"
      ],
      "metadata": {
        "id": "QYY-wCaHaizJ",
        "outputId": "05230a80-cf68-448c-a9b0-a73595ca9e2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4270, 0.9313, 0.6315, 0.8689],\n",
            "        [0.6734, 0.5307, 0.5362, 0.5707]]) \n",
            " tensor([[0.7517, 0.8675],\n",
            "        [0.7582, 0.7644]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a0 = torch.rand((4, 5), requires_grad=True)  # For the hidden layer\n",
        "b0 = torch.rand((2, 5), requires_grad=True)\n",
        "\n",
        "a1 = torch.rand((5, 2), requires_grad=True)  # For the output layer\n",
        "b1 = torch.rand((2, 2), requires_grad=True)\n",
        "\n",
        "\n",
        "print(a0,\n",
        "      \"\\n\\n\",b0,\n",
        "      \"\\n\\n\",a1,\n",
        "      \"\\n\\n\",b1)"
      ],
      "metadata": {
        "id": "tAYzBcaGeQs6",
        "outputId": "700f3777-01e7-4ef1-d1db-96f5134e26e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9368, 0.7348, 0.2154, 0.9532, 0.8344],\n",
            "        [0.4325, 0.3455, 0.2061, 0.1738, 0.7149],\n",
            "        [0.4404, 0.1564, 0.2872, 0.2801, 0.6692],\n",
            "        [0.2310, 0.9366, 0.4659, 0.5612, 0.1619]], requires_grad=True) \n",
            "\n",
            " tensor([[0.5816, 0.4139, 0.2252, 0.1493, 0.0464],\n",
            "        [0.2482, 0.5678, 0.7249, 0.9912, 0.5732]], requires_grad=True) \n",
            "\n",
            " tensor([[0.5713, 0.2372],\n",
            "        [0.9017, 0.5375],\n",
            "        [0.9669, 0.1608],\n",
            "        [0.6123, 0.1329],\n",
            "        [0.8466, 0.3913]], requires_grad=True) \n",
            "\n",
            " tensor([[0.8267, 0.4043],\n",
            "        [0.7303, 0.3179]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "quantiles = [0.2,0.5,0.75,0.9]\n",
        "\n",
        "def loss_function(output, target, quantile):\n",
        "    assert 0 < quantile < 1\n",
        "    errors = target - output\n",
        "    losses = torch.max((quantile - 1) * errors, quantile * errors)\n",
        "    return torch.abs(losses).mean()  # Use 'losses' instead of 'loss'\n",
        "\n",
        "for quantile in quantiles:\n",
        "    print(\"Quantile\", quantile)\n",
        "    # Forward Pass 1\n",
        "    y_1 = x @ a0 + b0\n",
        "    y_pred1 = y_1 @ a1 + b1\n",
        "\n",
        "    loss = loss_function(y_pred1, y, quantile)\n",
        "    print(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    # Updating Gradients\n",
        "    with torch.no_grad():\n",
        "        a0 -= 0.01 * a0.grad\n",
        "        b0 -= 0.01 * b0.grad\n",
        "        a1 -= 0.01 * a1.grad\n",
        "        b1 -= 0.01 * b1.grad\n",
        "\n",
        "    # Detach gradients after updating parameters\n",
        "    a0.grad = None\n",
        "    b0.grad = None\n",
        "    a1.grad = None\n",
        "    b1.grad = None\n",
        "\n",
        "    # Forward Pass 2\n",
        "    y_2 = x @ a0 + b0\n",
        "    y_pred2 = y_2 @ a1 + b1\n",
        "\n",
        "    loss = loss_function(y_pred2, y, quantile)\n",
        "    print(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    # Updating Gradients\n",
        "    with torch.no_grad():\n",
        "        a0 -= 0.01 * a0.grad\n",
        "        b0 -= 0.01 * b0.grad\n",
        "        a1 -= 0.01 * a1.grad\n",
        "        b1 -= 0.01 * b1.grad\n",
        "\n",
        "    # Detach gradients after updating parameters\n",
        "    a0.grad = None\n",
        "    b0.grad = None\n",
        "    a1.grad = None\n",
        "    b1.grad = None\n",
        "\n",
        "    # Forward Pass 3\n",
        "    y_3 = x @ a0 + b0\n",
        "    y_pred3 = y_3 @ a1 + b1\n",
        "\n",
        "    loss = loss_function(y_pred3, y, quantile)\n",
        "    print(loss.item())\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "gjiqN0QKoQ0a",
        "outputId": "0d54f4bd-9c32-49bc-caab-71167b37eb02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantile 0.2\n",
            "3.45569109916687\n",
            "3.386751890182495\n",
            "3.3188230991363525\n",
            "\n",
            "\n",
            "Quantile 0.5\n",
            "2.0742645263671875\n",
            "2.048081159591675\n",
            "2.0221362113952637\n",
            "\n",
            "\n",
            "Quantile 0.75\n",
            "1.0110681056976318\n",
            "1.0046335458755493\n",
            "0.9982280731201172\n",
            "\n",
            "\n",
            "Quantile 0.9\n",
            "0.3992912471294403\n",
            "0.3982703387737274\n",
            "0.3972512483596802\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Quantile 0.9 leads to lesser loss and is preferred"
      ],
      "metadata": {
        "id": "ZfSlnjG-wsSK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Adding a Activation function ReLU to see if loss improved:"
      ],
      "metadata": {
        "id": "rytwH1vww7O0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define trainable parameters\n",
        "\n",
        "\n",
        "quantiles = [0.2, 0.5, 0.75, 0.9]\n",
        "\n",
        "# Define the quantile loss function\n",
        "def loss_function(output, target, quantile):\n",
        "    assert 0 < quantile < 1\n",
        "    errors = target - output\n",
        "    losses = torch.max((quantile - 1) * errors, quantile * errors)\n",
        "    return torch.abs(losses).mean()\n",
        "\n",
        "for quantile in quantiles:\n",
        "    print(\"Quantile\", quantile)\n",
        "\n",
        "    # Forward Pass 1\n",
        "    y_1 = torch.matmul(x, a0) + b0\n",
        "    y_1f = nn.ReLU()\n",
        "    y_1_relu = y_1f(y_1)\n",
        "    y_pred1 = torch.matmul(y_1_relu, a1) + b1\n",
        "\n",
        "    loss = loss_function(y_pred1, y, quantile)\n",
        "    print(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    # Updating Gradients\n",
        "    with torch.no_grad():\n",
        "        a0 -= 0.01 * a0.grad\n",
        "        b0 -= 0.01 * b0.grad\n",
        "        a1 -= 0.01 * a1.grad\n",
        "        b1 -= 0.01 * b1.grad\n",
        "\n",
        "    # Detach gradients after updating parameters\n",
        "    a0.grad = None\n",
        "    b0.grad = None\n",
        "    a1.grad = None\n",
        "    b1.grad = None\n",
        "\n",
        "    # Forward Pass 2\n",
        "    y_2 = torch.matmul(x, a0) + b0\n",
        "    y_2f = nn.ReLU()\n",
        "    y_2_relu = y_2f(y_2)\n",
        "    y_pred2 = torch.matmul(y_2_relu, a1) + b1\n",
        "\n",
        "\n",
        "    loss = loss_function(y_pred2, y, quantile)\n",
        "    print(loss.item())\n",
        "    loss.backward()\n",
        "\n",
        "    # Updating Gradients\n",
        "    with torch.no_grad():\n",
        "        a0 -= 0.01 * a0.grad\n",
        "        b0 -= 0.01 * b0.grad\n",
        "        a1 -= 0.01 * a1.grad\n",
        "        b1 -= 0.01 * b1.grad\n",
        "\n",
        "    # Detach gradients after updating parameters\n",
        "    a0.grad = None\n",
        "    b0.grad = None\n",
        "    a1.grad = None\n",
        "    b1.grad = None\n",
        "\n",
        "    # Forward Pass 3\n",
        "    y_3 = torch.matmul(x, a0) + b0\n",
        "    y_3f = nn.ReLU()\n",
        "    y_3_relu = y_3f(y_3)\n",
        "    y_pred3 = torch.matmul(y_3_relu, a1) + b1\n",
        "\n",
        "    loss = loss_function(y_pred3, y, quantile)\n",
        "    print(loss.item())\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "FnspAsEQdhYQ",
        "outputId": "b3477fb0-d71c-428f-dcc5-405fa42c4c25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantile 0.2\n",
            "3.1780099868774414\n",
            "3.113114356994629\n",
            "3.0491526126861572\n",
            "\n",
            "\n",
            "Quantile 0.5\n",
            "1.9057204723358154\n",
            "1.8810606002807617\n",
            "1.8566211462020874\n",
            "\n",
            "\n",
            "Quantile 0.75\n",
            "0.9283105731010437\n",
            "0.9222484827041626\n",
            "0.9162132740020752\n",
            "\n",
            "\n",
            "Quantile 0.9\n",
            "0.3664852976799011\n",
            "0.3655233383178711\n",
            "0.3645630478858948\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not much change"
      ],
      "metadata": {
        "id": "UEsPMErRxFTK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Another Way of Implmentation"
      ],
      "metadata": {
        "id": "tbeSMtFzaFbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ],
      "metadata": {
        "id": "wxaVhUJH0P0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "\n",
        "# Convert the training data into a PyTorch Dataset\n",
        "dataset = TensorDataset(x, y)\n",
        "\n",
        "# Create a DataLoader to handle batching and shuffling\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "KOLfeeT03atv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantiles = [0.2,0.5,0.75,0.9]"
      ],
      "metadata": {
        "id": "an__4Df8RjdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple neural network architecture\n",
        "import torch.nn as nn\n",
        "\n",
        "class QuantileNet(nn.Module):\n",
        "    def __init__(self, output_size):\n",
        "        super(QuantileNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 5)  # Input features are 4-dimensional, hidden layer has 5 neurons\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(5, 2)  # Output layer with 2 nodes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu1(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model for batch training\n",
        "model = QuantileNet(output_size = 2)\n",
        "\n",
        "# Define optimizer for batch training\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training parameters\n",
        "epochs = 100\n",
        "batch_size = 256\n",
        "\n",
        "# Convert the training data into a PyTorch Dataset\n",
        "dataset = TensorDataset(x, y)\n",
        "\n",
        "# Create a DataLoader to handle batching and shuffling\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "for quantile in quantiles:\n",
        "  print(\"Quantile\", quantile)\n",
        "  # Training loop with DataLoader\n",
        "  model.train()\n",
        "  for epoch in range(epochs):\n",
        "      for x_batch, y_batch in dataloader:\n",
        "          optimizer.zero_grad()\n",
        "          preds = model(x_batch)\n",
        "          loss = loss_function(preds, y_batch, quantile)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "\n",
        "      if epoch % 10 == 0:\n",
        "          print(f'Epoch {epoch}, Loss: {loss.item()}')\n"
      ],
      "metadata": {
        "id": "d8HIiNAln6Pu",
        "outputId": "a705f3c4-ee25-4241-a4e7-9c6001bcaf3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantile 0.2\n",
            "Epoch 0, Loss: 0.1418529897928238\n",
            "Epoch 10, Loss: 0.13604535162448883\n",
            "Epoch 20, Loss: 0.13031037151813507\n",
            "Epoch 30, Loss: 0.12430799752473831\n",
            "Epoch 40, Loss: 0.11789591610431671\n",
            "Epoch 50, Loss: 0.11133801192045212\n",
            "Epoch 60, Loss: 0.10463184118270874\n",
            "Epoch 70, Loss: 0.09775042533874512\n",
            "Epoch 80, Loss: 0.09066101908683777\n",
            "Epoch 90, Loss: 0.08332854509353638\n",
            "Quantile 0.5\n",
            "Epoch 0, Loss: 0.18928956985473633\n",
            "Epoch 10, Loss: 0.16224072873592377\n",
            "Epoch 20, Loss: 0.13485389947891235\n",
            "Epoch 30, Loss: 0.11073343455791473\n",
            "Epoch 40, Loss: 0.08734513819217682\n",
            "Epoch 50, Loss: 0.06545980274677277\n",
            "Epoch 60, Loss: 0.0445280447602272\n",
            "Epoch 70, Loss: 0.024040378630161285\n",
            "Epoch 80, Loss: 0.016097448766231537\n",
            "Epoch 90, Loss: 0.012697696685791016\n",
            "Quantile 0.75\n",
            "Epoch 0, Loss: 0.016774937510490417\n",
            "Epoch 10, Loss: 0.01466095820069313\n",
            "Epoch 20, Loss: 0.010779239237308502\n",
            "Epoch 30, Loss: 0.00640222430229187\n",
            "Epoch 40, Loss: 0.006576176732778549\n",
            "Epoch 50, Loss: 0.006192296743392944\n",
            "Epoch 60, Loss: 0.006203554570674896\n",
            "Epoch 70, Loss: 0.0059655942022800446\n",
            "Epoch 80, Loss: 0.005696333944797516\n",
            "Epoch 90, Loss: 0.005673736333847046\n",
            "Quantile 0.9\n",
            "Epoch 0, Loss: 0.0022355124820023775\n",
            "Epoch 10, Loss: 0.0023386867251247168\n",
            "Epoch 20, Loss: 0.0023161321878433228\n",
            "Epoch 30, Loss: 0.002515502506867051\n",
            "Epoch 40, Loss: 0.0021733136381953955\n",
            "Epoch 50, Loss: 0.002274735365062952\n",
            "Epoch 60, Loss: 0.002230761805549264\n",
            "Epoch 70, Loss: 0.002199889626353979\n",
            "Epoch 80, Loss: 0.002505424665287137\n",
            "Epoch 90, Loss: 0.0023246929049491882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "izhl-9Wta_uu"
      }
    }
  ]
}